{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:13.332208Z","iopub.execute_input":"2024-04-05T11:53:13.332669Z","iopub.status.idle":"2024-04-05T11:53:17.895481Z","shell.execute_reply.started":"2024-04-05T11:53:13.332626Z","shell.execute_reply":"2024-04-05T11:53:17.894675Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import BertForTokenClassification, BertTokenizerFast\nfrom transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:17.897359Z","iopub.execute_input":"2024-04-05T11:53:17.897842Z","iopub.status.idle":"2024-04-05T11:53:32.548691Z","shell.execute_reply.started":"2024-04-05T11:53:17.897809Z","shell.execute_reply":"2024-04-05T11:53:32.547860Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-05 11:53:24.364677: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-05 11:53:24.364782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-05 11:53:24.496263: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') #using gpu","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:32.549740Z","iopub.execute_input":"2024-04-05T11:53:32.550248Z","iopub.status.idle":"2024-04-05T11:53:32.585067Z","shell.execute_reply.started":"2024-04-05T11:53:32.550224Z","shell.execute_reply":"2024-04-05T11:53:32.584002Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(\"conll2003\") #we will be using the conll2003 dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:32.588212Z","iopub.execute_input":"2024-04-05T11:53:32.588547Z","iopub.status.idle":"2024-04-05T11:53:43.990127Z","shell.execute_reply.started":"2024-04-05T11:53:32.588522Z","shell.execute_reply":"2024-04-05T11:53:43.989102Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f952c16e7754b588be81628c693689b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.62k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f665125621344b1bed645c66402ef16"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset conll2003/conll2003 (download: 959.94 KiB, generated: 9.78 MiB, post-processed: Unknown size, total: 10.72 MiB) to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/983k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b20c6e1ab5b84154a021cd325595b784"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/14042 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3251 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/3454 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset conll2003 downloaded and prepared to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76eb8cf71eea4aeba0950ed376109ffd"}},"metadata":{}}]},{"cell_type":"code","source":"dataset #viewing and understanding the structure of dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:43.991339Z","iopub.execute_input":"2024-04-05T11:53:43.991623Z","iopub.status.idle":"2024-04-05T11:53:43.998883Z","shell.execute_reply.started":"2024-04-05T11:53:43.991598Z","shell.execute_reply":"2024-04-05T11:53:43.997962Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14042\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3251\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3454\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"text_example = dataset['train'][0]\ntext_example #viewing a sample of the dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:44.000885Z","iopub.execute_input":"2024-04-05T11:53:44.002352Z","iopub.status.idle":"2024-04-05T11:53:44.093172Z","shell.execute_reply.started":"2024-04-05T11:53:44.002291Z","shell.execute_reply":"2024-04-05T11:53:44.092178Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'id': '0',\n 'tokens': ['EU',\n  'rejects',\n  'German',\n  'call',\n  'to',\n  'boycott',\n  'British',\n  'lamb',\n  '.'],\n 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0]}"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\") #setting up the tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:44.094402Z","iopub.execute_input":"2024-04-05T11:53:44.094715Z","iopub.status.idle":"2024-04-05T11:53:46.909566Z","shell.execute_reply.started":"2024-04-05T11:53:44.094690Z","shell.execute_reply":"2024-04-05T11:53:46.908318Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82ec1e05d1744f3d9c770851beb56799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a290ca4e773d4e7cacde89db6ea8eb61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8debe387b7b84d02be46f85bfc5656e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02850edcfd5b4b23a71c603a7912fb80"}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_input = tokenizer(text_example['tokens'], is_split_into_words = True)\ntokenized_input #using the sample to check if tokenizer is set up correctly","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.911420Z","iopub.execute_input":"2024-04-05T11:53:46.911802Z","iopub.status.idle":"2024-04-05T11:53:46.921681Z","shell.execute_reply.started":"2024-04-05T11:53:46.911767Z","shell.execute_reply":"2024-04-05T11:53:46.920594Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 7327, 19164, 2446, 2655, 2000, 17757, 2329, 12559, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"tokens = tokenizer.convert_ids_to_tokens(tokenized_input['input_ids']) #converting to tokens\ntokens","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.925477Z","iopub.execute_input":"2024-04-05T11:53:46.925821Z","iopub.status.idle":"2024-04-05T11:53:46.935448Z","shell.execute_reply.started":"2024-04-05T11:53:46.925795Z","shell.execute_reply":"2024-04-05T11:53:46.934463Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['[CLS]',\n 'eu',\n 'rejects',\n 'german',\n 'call',\n 'to',\n 'boycott',\n 'british',\n 'lamb',\n '.',\n '[SEP]']"},"metadata":{}}]},{"cell_type":"code","source":"word_ids = tokenized_input.word_ids()\nword_ids #checking the word ids of the sample","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.939680Z","iopub.execute_input":"2024-04-05T11:53:46.940407Z","iopub.status.idle":"2024-04-05T11:53:46.949968Z","shell.execute_reply.started":"2024-04-05T11:53:46.940371Z","shell.execute_reply":"2024-04-05T11:53:46.949356Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, None]"},"metadata":{}}]},{"cell_type":"code","source":"#two additional tokens [CLS] and [SEP] come up. Additionally, problem of sub token arises as the tokenizer can also cut down a word into multiple pieces(not shown in the above example)\n#therefore, we define a function to tackle both of these problems","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.951054Z","iopub.execute_input":"2024-04-05T11:53:46.951354Z","iopub.status.idle":"2024-04-05T11:53:46.956352Z","shell.execute_reply.started":"2024-04-05T11:53:46.951322Z","shell.execute_reply":"2024-04-05T11:53:46.955638Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def neg100_plus_subword_adjust(input_data, label_all_tokens = True):\n    tokenized_input = tokenizer(input_data['tokens'], truncation = True , is_split_into_words = True) #tokenizing the input data\n    labels = [] #initialising labels array to collect \n    for i, label in enumerate(input_data[\"ner_tags\"]):\n        word_ids = tokenized_input.word_ids(batch_index = i) #generating word ids for i\n        previous_word_idx = None #setting previous word idx back to none\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None: #handling the None case\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx]) #base case\n            else:\n                label_ids.append(label[word_idx] if label_all_tokens else -100) #subword problem handling\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n    tokenized_input[\"labels\"] = labels #adding labels as a new key-value pair to tokenized_input\n    return tokenized_input","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.957815Z","iopub.execute_input":"2024-04-05T11:53:46.958693Z","iopub.status.idle":"2024-04-05T11:53:46.969318Z","shell.execute_reply.started":"2024-04-05T11:53:46.958660Z","shell.execute_reply":"2024-04-05T11:53:46.967651Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"z = neg100_plus_subword_adjust(dataset['train'][4:6])\nprint(z) #checking if the function works","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.970587Z","iopub.execute_input":"2024-04-05T11:53:46.970920Z","iopub.status.idle":"2024-04-05T11:53:46.983781Z","shell.execute_reply.started":"2024-04-05T11:53:46.970893Z","shell.execute_reply":"2024-04-05T11:53:46.982729Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"{'input_ids': [[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647, 2586, 1005, 1055, 15651, 2837, 14121, 1062, 9328, 5804, 2056, 2006, 9317, 10390, 2323, 4965, 8351, 4168, 4017, 2013, 3032, 2060, 2084, 3725, 2127, 1996, 4045, 6040, 2001, 24509, 1012, 102], [101, 1000, 2057, 2079, 1050, 1005, 1056, 2490, 2151, 2107, 12832, 2138, 2057, 2079, 1050, 1005, 1056, 2156, 2151, 5286, 2005, 2009, 1010, 1000, 1996, 3222, 1005, 1055, 2708, 14056, 24794, 2271, 3158, 4315, 14674, 2409, 1037, 2739, 27918, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, -100]]}\n","output_type":"stream"}]},{"cell_type":"code","source":"for token, label in zip(tokenizer.convert_ids_to_tokens(z['input_ids'][0]), z['labels'][0]):\n    print(f\"{token:_<40} {label}\") #arranging tokens and corresponding ner tags side by side","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.987371Z","iopub.execute_input":"2024-04-05T11:53:46.988263Z","iopub.status.idle":"2024-04-05T11:53:46.994276Z","shell.execute_reply.started":"2024-04-05T11:53:46.988233Z","shell.execute_reply":"2024-04-05T11:53:46.993344Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[CLS]___________________________________ -100\ngermany_________________________________ 5\n'_______________________________________ 0\ns_______________________________________ 0\nrepresentative__________________________ 0\nto______________________________________ 0\nthe_____________________________________ 0\neuropean________________________________ 3\nunion___________________________________ 4\n'_______________________________________ 0\ns_______________________________________ 0\nveterinary______________________________ 0\ncommittee_______________________________ 0\nwerner__________________________________ 1\nz_______________________________________ 2\n##wing__________________________________ 2\n##mann__________________________________ 2\nsaid____________________________________ 0\non______________________________________ 0\nwednesday_______________________________ 0\nconsumers_______________________________ 0\nshould__________________________________ 0\nbuy_____________________________________ 0\nsheep___________________________________ 0\n##me____________________________________ 0\n##at____________________________________ 0\nfrom____________________________________ 0\ncountries_______________________________ 0\nother___________________________________ 0\nthan____________________________________ 0\nbritain_________________________________ 5\nuntil___________________________________ 0\nthe_____________________________________ 0\nscientific______________________________ 0\nadvice__________________________________ 0\nwas_____________________________________ 0\nclearer_________________________________ 0\n._______________________________________ 0\n[SEP]___________________________________ -100\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_dataset = dataset.map(neg100_plus_subword_adjust, batched = True) #using the function to tokenize the whole dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:46.995263Z","iopub.execute_input":"2024-04-05T11:53:46.995667Z","iopub.status.idle":"2024-04-05T11:53:50.637241Z","shell.execute_reply.started":"2024-04-05T11:53:46.995644Z","shell.execute_reply":"2024-04-05T11:53:50.636487Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c30e949b16794fd89f50188034b58e5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c58b30bd90ed4067ba4608635d948501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f50b881e5b574db8b95dbbb8cc431b06"}},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained('bert-base-uncased', num_labels = 9).to(device) #initialising the bert model","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:53:50.638413Z","iopub.execute_input":"2024-04-05T11:53:50.639092Z","iopub.status.idle":"2024-04-05T11:54:02.984696Z","shell.execute_reply.started":"2024-04-05T11:53:50.639057Z","shell.execute_reply":"2024-04-05T11:54:02.983874Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95bde6d421f5452f835a7010691e78c1"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\nargs = TrainingArguments( # setting up the training arguments\n    \"test-ner\",\n    evaluation_strategy = \"epoch\",\n    learning_rate = 2e-5,\n    per_device_train_batch_size = 16,\n    per_device_eval_batch_size = 16,\n    num_train_epochs = 1,\n    weight_decay = 0.01,\n        \n)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:02.985788Z","iopub.execute_input":"2024-04-05T11:54:02.986062Z","iopub.status.idle":"2024-04-05T11:54:03.029051Z","shell.execute_reply.started":"2024-04-05T11:54:02.986038Z","shell.execute_reply":"2024-04-05T11:54:03.028280Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer) #we use data collator to arrange, batch and pad the dataset","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:03.030288Z","iopub.execute_input":"2024-04-05T11:54:03.030655Z","iopub.status.idle":"2024-04-05T11:54:03.035275Z","shell.execute_reply.started":"2024-04-05T11:54:03.030620Z","shell.execute_reply":"2024-04-05T11:54:03.034241Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"pip install seqeval","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:03.036422Z","iopub.execute_input":"2024-04-05T11:54:03.036706Z","iopub.status.idle":"2024-04-05T11:54:19.496991Z","shell.execute_reply.started":"2024-04-05T11:54:03.036683Z","shell.execute_reply":"2024-04-05T11:54:19.495522Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=b38d69ea62ef0f38cb70ba61089d9340eb8a9d27f624d6612354682d4c17bacd\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_metric\nmetric = load_metric('seqeval') #using seqeval as a metric calculator","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:19.498881Z","iopub.execute_input":"2024-04-05T11:54:19.499283Z","iopub.status.idle":"2024-04-05T11:54:20.707631Z","shell.execute_reply.started":"2024-04-05T11:54:19.499249Z","shell.execute_reply":"2024-04-05T11:54:20.706851Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32ed5cff646f4c60bb208bdfba3598c7"}},"metadata":{}}]},{"cell_type":"code","source":"metric","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:20.709024Z","iopub.execute_input":"2024-04-05T11:54:20.709377Z","iopub.status.idle":"2024-04-05T11:54:20.715870Z","shell.execute_reply.started":"2024-04-05T11:54:20.709345Z","shell.execute_reply":"2024-04-05T11:54:20.714897Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Metric(name: \"seqeval\", features: {'predictions': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='label'), length=-1, id='sequence')}, usage: \"\"\"\nProduces labelling scores along with its sufficient statistics\nfrom a source against one or more references.\n\nArgs:\n    predictions: List of List of predicted labels (Estimated targets as returned by a tagger)\n    references: List of List of reference labels (Ground truth (correct) target values)\n    suffix: True if the IOB prefix is after type, False otherwise. default: False\n    scheme: Specify target tagging scheme. Should be one of [\"IOB1\", \"IOB2\", \"IOE1\", \"IOE2\", \"IOBES\", \"BILOU\"].\n        default: None\n    mode: Whether to count correct entity labels with incorrect I/B tags as true positives or not.\n        If you want to only count exact matches, pass mode=\"strict\". default: None.\n    sample_weight: Array-like of shape (n_samples,), weights for individual samples. default: None\n    zero_division: Which value to substitute as a metric value when encountering zero division. Should be on of 0, 1,\n        \"warn\". \"warn\" acts as 0, but the warning is raised.\n\nReturns:\n    'scores': dict. Summary of the scores for overall and per type\n        Overall:\n            'accuracy': accuracy,\n            'precision': precision,\n            'recall': recall,\n            'f1': F1 score, also known as balanced F-score or F-measure,\n        Per type:\n            'precision': precision,\n            'recall': recall,\n            'f1': F1 score, also known as balanced F-score or F-measure\nExamples:\n\n    >>> predictions = [['O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n    >>> references = [['O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'O'], ['B-PER', 'I-PER', 'O']]\n    >>> seqeval = datasets.load_metric(\"seqeval\")\n    >>> results = seqeval.compute(predictions=predictions, references=references)\n    >>> print(list(results.keys()))\n    ['MISC', 'PER', 'overall_precision', 'overall_recall', 'overall_f1', 'overall_accuracy']\n    >>> print(results[\"overall_f1\"])\n    0.5\n    >>> print(results[\"PER\"][\"f1\"])\n    1.0\n\"\"\", stored examples: 0)"},"metadata":{}}]},{"cell_type":"code","source":"label_list = dataset['train'].features['ner_tags'].feature.names\nlabel_list","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:20.717210Z","iopub.execute_input":"2024-04-05T11:54:20.717530Z","iopub.status.idle":"2024-04-05T11:54:20.726725Z","shell.execute_reply.started":"2024-04-05T11:54:20.717488Z","shell.execute_reply":"2024-04-05T11:54:20.725724Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"},"metadata":{}}]},{"cell_type":"code","source":"labels = [label_list[i] for i in text_example[\"ner_tags\"]]#text_example, as referred above, is the first row in the training dataset\nmetric.compute(predictions=[labels], references=[labels])#to check if the metric works correctly","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:20.727974Z","iopub.execute_input":"2024-04-05T11:54:20.728300Z","iopub.status.idle":"2024-04-05T11:54:20.745806Z","shell.execute_reply.started":"2024-04-05T11:54:20.728268Z","shell.execute_reply":"2024-04-05T11:54:20.744798Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 2},\n 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 1.0,\n 'overall_f1': 1.0,\n 'overall_accuracy': 1.0}"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(eval_preds):#eval fxn\n    pred_logits, labels = eval_preds\n    pred_logits = np.argmax(pred_logits, axis = 2)\n    #setting up lists for metric.compute\n    predictions = [\n        [label_list[eval_preds] for (eval_preds, l) in zip(prediction, label) if l != -100] \n        for prediction, label in zip(pred_logits, labels) \n    ]\n    true_labels = [#\n      [label_list[l] for (eval_preds, l) in zip(prediction, label) if l != -100] \n       for prediction, label in zip(pred_logits, labels) \n   ]\n    #applying metric.compute\n    results = metric.compute(predictions=predictions, references=true_labels) \n    return { \n       \"precision\": results[\"overall_precision\"], \n       \"recall\": results[\"overall_recall\"], \n       \"f1\": results[\"overall_f1\"], \n      \"accuracy\": results[\"overall_accuracy\"], \n      } ","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:20.747109Z","iopub.execute_input":"2024-04-05T11:54:20.747766Z","iopub.status.idle":"2024-04-05T11:54:20.755789Z","shell.execute_reply.started":"2024-04-05T11:54:20.747731Z","shell.execute_reply":"2024-04-05T11:54:20.754794Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer( #setting up Trainer\n    model, \n    args, \n   train_dataset=tokenized_dataset[\"train\"], \n   eval_dataset=tokenized_dataset[\"validation\"], \n   data_collator=data_collator, \n   tokenizer=tokenizer, \n   compute_metrics=compute_metrics \n)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:20.757408Z","iopub.execute_input":"2024-04-05T11:54:20.758126Z","iopub.status.idle":"2024-04-05T11:54:21.418559Z","shell.execute_reply.started":"2024-04-05T11:54:20.758089Z","shell.execute_reply":"2024-04-05T11:54:21.417614Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train() #training","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:54:21.419794Z","iopub.execute_input":"2024-04-05T11:54:21.420089Z","iopub.status.idle":"2024-04-05T11:57:06.030700Z","shell.execute_reply.started":"2024-04-05T11:54:21.420064Z","shell.execute_reply":"2024-04-05T11:57:06.029653Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240405_115450-i74616cu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ayush8rai/huggingface/runs/i74616cu' target=\"_blank\">romulan-data-4</a></strong> to <a href='https://wandb.ai/ayush8rai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ayush8rai/huggingface' target=\"_blank\">https://wandb.ai/ayush8rai/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ayush8rai/huggingface/runs/i74616cu' target=\"_blank\">https://wandb.ai/ayush8rai/huggingface/runs/i74616cu</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='878' max='878' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [878/878 01:42, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.226900</td>\n      <td>0.069167</td>\n      <td>0.908322</td>\n      <td>0.925495</td>\n      <td>0.916828</td>\n      <td>0.981032</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=878, training_loss=0.16607801137589648, metrics={'train_runtime': 164.2349, 'train_samples_per_second': 85.499, 'train_steps_per_second': 5.346, 'total_flos': 341037325138356.0, 'train_loss': 0.16607801137589648, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"ner_model\") #saving model","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.032164Z","iopub.execute_input":"2024-04-05T11:57:06.032566Z","iopub.status.idle":"2024-04-05T11:57:06.857767Z","shell.execute_reply.started":"2024-04-05T11:57:06.032520Z","shell.execute_reply":"2024-04-05T11:57:06.856743Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"tokenizer.save_pretrained(\"tokenizer\") #saving tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.863659Z","iopub.execute_input":"2024-04-05T11:57:06.863965Z","iopub.status.idle":"2024-04-05T11:57:06.888285Z","shell.execute_reply.started":"2024-04-05T11:57:06.863938Z","shell.execute_reply":"2024-04-05T11:57:06.887327Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"('tokenizer/tokenizer_config.json',\n 'tokenizer/special_tokens_map.json',\n 'tokenizer/vocab.txt',\n 'tokenizer/added_tokens.json',\n 'tokenizer/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"id2label = {\n    str(i): label for i,label in enumerate(label_list)\n}\nlabel2id = {\n    label: str(i) for i,label in enumerate(label_list)\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.889497Z","iopub.execute_input":"2024-04-05T11:57:06.889845Z","iopub.status.idle":"2024-04-05T11:57:06.896617Z","shell.execute_reply.started":"2024-04-05T11:57:06.889813Z","shell.execute_reply":"2024-04-05T11:57:06.895598Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"import json","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.897853Z","iopub.execute_input":"2024-04-05T11:57:06.898122Z","iopub.status.idle":"2024-04-05T11:57:06.908690Z","shell.execute_reply.started":"2024-04-05T11:57:06.898099Z","shell.execute_reply":"2024-04-05T11:57:06.907842Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"config = json.load(open(\"ner_model/config.json\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.909972Z","iopub.execute_input":"2024-04-05T11:57:06.910405Z","iopub.status.idle":"2024-04-05T11:57:06.917501Z","shell.execute_reply.started":"2024-04-05T11:57:06.910374Z","shell.execute_reply":"2024-04-05T11:57:06.916528Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"config[\"id2label\"] = id2label\nconfig[\"label2id\"] = label2id","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.918944Z","iopub.execute_input":"2024-04-05T11:57:06.919197Z","iopub.status.idle":"2024-04-05T11:57:06.929758Z","shell.execute_reply.started":"2024-04-05T11:57:06.919176Z","shell.execute_reply":"2024-04-05T11:57:06.928704Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"json.dump(config, open(\"ner_model/config.json\",\"w\"))","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.930922Z","iopub.execute_input":"2024-04-05T11:57:06.931246Z","iopub.status.idle":"2024-04-05T11:57:06.939348Z","shell.execute_reply.started":"2024-04-05T11:57:06.931218Z","shell.execute_reply":"2024-04-05T11:57:06.938351Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model_fine_tuned = AutoModelForTokenClassification.from_pretrained(\"ner_model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:06.940631Z","iopub.execute_input":"2024-04-05T11:57:06.940963Z","iopub.status.idle":"2024-04-05T11:57:07.191761Z","shell.execute_reply.started":"2024-04-05T11:57:06.940933Z","shell.execute_reply":"2024-04-05T11:57:07.190782Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline #using pipeline","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:07.193137Z","iopub.execute_input":"2024-04-05T11:57:07.193468Z","iopub.status.idle":"2024-04-05T11:57:08.527349Z","shell.execute_reply.started":"2024-04-05T11:57:07.193439Z","shell.execute_reply":"2024-04-05T11:57:08.526077Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"nlp = pipeline(\"ner\", model=model_fine_tuned, tokenizer=tokenizer)#setting up pipeline","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:08.528817Z","iopub.execute_input":"2024-04-05T11:57:08.529112Z","iopub.status.idle":"2024-04-05T11:57:08.539108Z","shell.execute_reply.started":"2024-04-05T11:57:08.529085Z","shell.execute_reply":"2024-04-05T11:57:08.537925Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#assume you are in 2003 or before while trying out the model below :-","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:08.541131Z","iopub.execute_input":"2024-04-05T11:57:08.541886Z","iopub.status.idle":"2024-04-05T11:57:08.546635Z","shell.execute_reply.started":"2024-04-05T11:57:08.541853Z","shell.execute_reply":"2024-04-05T11:57:08.545565Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"example = \"Henry Ford, the founder of Ford Motor Company, was born in Michigan, United States of America\"\nner_results = nlp(example)\nprint(ner_results)","metadata":{"execution":{"iopub.status.busy":"2024-04-05T11:57:08.547872Z","iopub.execute_input":"2024-04-05T11:57:08.548281Z","iopub.status.idle":"2024-04-05T11:57:08.696519Z","shell.execute_reply.started":"2024-04-05T11:57:08.548242Z","shell.execute_reply":"2024-04-05T11:57:08.695273Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"[{'entity': 'B-PER', 'score': 0.95669186, 'index': 1, 'word': 'henry', 'start': 0, 'end': 5}, {'entity': 'I-PER', 'score': 0.9199473, 'index': 2, 'word': 'ford', 'start': 6, 'end': 10}, {'entity': 'B-ORG', 'score': 0.8947865, 'index': 7, 'word': 'ford', 'start': 27, 'end': 31}, {'entity': 'I-ORG', 'score': 0.8595338, 'index': 8, 'word': 'motor', 'start': 32, 'end': 37}, {'entity': 'I-ORG', 'score': 0.9048448, 'index': 9, 'word': 'company', 'start': 38, 'end': 45}, {'entity': 'B-LOC', 'score': 0.9842651, 'index': 14, 'word': 'michigan', 'start': 59, 'end': 67}, {'entity': 'B-LOC', 'score': 0.97773564, 'index': 16, 'word': 'united', 'start': 69, 'end': 75}, {'entity': 'I-LOC', 'score': 0.7145643, 'index': 17, 'word': 'states', 'start': 76, 'end': 82}, {'entity': 'I-LOC', 'score': 0.5217796, 'index': 18, 'word': 'of', 'start': 83, 'end': 85}, {'entity': 'I-LOC', 'score': 0.85132134, 'index': 19, 'word': 'america', 'start': 86, 'end': 93}]\n","output_type":"stream"}]}]}